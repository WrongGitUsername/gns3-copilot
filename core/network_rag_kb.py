#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAG-based network command knowledge base.

Uses LangChain to vectorize network troubleshooting books and intelligently retrieve related commands.
"""

import os
import sys
from typing import List, Dict, Optional
from pathlib import Path

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

# Import language adapter
try:
    from .language_adapter import get_message, language_adapter
    LANGUAGE_ADAPTER_AVAILABLE = True
except ImportError:
    LANGUAGE_ADAPTER_AVAILABLE = False

try:
    # Try new version import (langchain-huggingface)
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_community.vectorstores import FAISS
    from langchain_community.document_loaders import (
        PyPDFLoader, 
        TextLoader, 
        UnstructuredMarkdownLoader,
        DirectoryLoader
    )
except ImportError:
    try:
        # Fallback to community version
        from langchain_community.embeddings import HuggingFaceEmbeddings
        from langchain_community.vectorstores import FAISS
        from langchain_community.document_loaders import (
            PyPDFLoader, 
            TextLoader, 
            UnstructuredMarkdownLoader,
            DirectoryLoader
        )
    except ImportError:
        # Final fallback to old version import
        from langchain.embeddings import HuggingFaceEmbeddings
        from langchain.vectorstores import FAISS
        from langchain.document_loaders import (
            PyPDFLoader, 
            TextLoader, 
            UnstructuredMarkdownLoader,
            DirectoryLoader
        )

from .bge_m3_config import BGEM3Config

class NetworkTroubleshootingRAG:
    """ç½‘ç»œæ’é”™RAGçŸ¥è¯†åº“"""
    
    def __init__(self, knowledge_base_path: str = "./knowledge_base", 
                 vector_store_path: str = "./vector_store",
                 config_path: str = "rag_config.ini"):
        """
        åˆå§‹åŒ–RAGçŸ¥è¯†åº“
        
        Args:
            knowledge_base_path: çŸ¥è¯†åº“æ–‡æ¡£è·¯å¾„
            vector_store_path: å‘é‡å­˜å‚¨è·¯å¾„
            config_path: BGE-M3é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.knowledge_base_path = Path(knowledge_base_path)
        self.vector_store_path = Path(vector_store_path)
        
        # åŠ è½½BGE-M3é…ç½®
        self.config = BGEM3Config(config_path)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.knowledge_base_path.mkdir(exist_ok=True)
        self.vector_store_path.mkdir(exist_ok=True)
        
        # ä½¿ç”¨é…ç½®åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        embedding_config = self.config.get_embedding_config()
        self.embeddings = HuggingFaceEmbeddings(**embedding_config)
        
        # ä½¿ç”¨é…ç½®åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
        splitter_config = self.config.get_text_splitter_config()
        self.text_splitter = RecursiveCharacterTextSplitter(**splitter_config)
        
        self.vector_store = None
        self._load_or_create_vector_store()
    
    def build_vector_store(self):
        """æ„å»ºå‘é‡å­˜å‚¨ï¼ˆé‡æ–°å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼‰"""
        if LANGUAGE_ADAPTER_AVAILABLE:
            print(get_message("vector_store_rebuilding"))
        else:
            print("ğŸ”„ Force rebuilding vector store...")
        
        # åˆ é™¤ç°æœ‰å‘é‡å­˜å‚¨
        if self.vector_store_path.exists():
            import shutil
            shutil.rmtree(self.vector_store_path)
            self.vector_store_path.mkdir(exist_ok=True)
        
        # é‡æ–°è°ƒç”¨add_documents_from_directoryæ¥é‡å»º
        success = self.add_documents_from_directory()
        if success:
            if LANGUAGE_ADAPTER_AVAILABLE:
                print(get_message("vector_store_rebuilt"))
            else:
                print("âœ… Vector store rebuild completed")
        else:
            if LANGUAGE_ADAPTER_AVAILABLE:
                print(get_message("no_documents_for_vector_store"))
            else:
                print("âŒ No documents available for building vector store")
    
    def add_documents_from_directory(self, directory_path: str = None):
        """ä»ç›®å½•åŠ è½½å¹¶å‘é‡åŒ–æ–‡æ¡£"""
        if directory_path is None:
            directory_path = self.knowledge_base_path
            
        if LANGUAGE_ADAPTER_AVAILABLE:
            print(get_message("loading_documents_from", directory_path))
        else:
            print(f"ğŸ“š Starting to load documents from: {directory_path}")
        
        # æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼
        loaders = [
            DirectoryLoader(directory_path, glob="**/*.pdf", loader_cls=PyPDFLoader),
            DirectoryLoader(directory_path, glob="**/*.txt", loader_cls=TextLoader),
            DirectoryLoader(directory_path, glob="**/*.md", loader_cls=UnstructuredMarkdownLoader),
        ]
        
        documents = []
        for loader in loaders:
            try:
                docs = loader.load()
                documents.extend(docs)
                if LANGUAGE_ADAPTER_AVAILABLE:
                    print(get_message("documents_loaded", len(docs)))
                else:
                    print(f"âœ… Loaded {len(docs)} documents")
            except Exception as e:
                if LANGUAGE_ADAPTER_AVAILABLE:
                    print(get_message("document_loading_error", str(e)))
                else:
                    print(f"âš ï¸ Error loading documents: {e}")
        
        if not documents:
            if LANGUAGE_ADAPTER_AVAILABLE:
                print(get_message("no_documents_for_vector_store"))
            else:
                print("âŒ No documents found")
            return False
        
        # åˆ†å‰²æ–‡æ¡£
        if LANGUAGE_ADAPTER_AVAILABLE:
            print(get_message("splitting_documents"))
        else:
            print("ğŸ”§ Splitting documents...")
        split_docs = self.text_splitter.split_documents(documents)
        if LANGUAGE_ADAPTER_AVAILABLE:
            print(get_message("documents_split", len(split_docs)))
        else:
            print(f"ğŸ“„ Split into {len(split_docs)} document chunks")
        
        # åˆ›å»ºå‘é‡å­˜å‚¨
        if LANGUAGE_ADAPTER_AVAILABLE:
            print(get_message("creating_vector_embeddings"))
        else:
            print("ğŸ§  Creating vector embeddings...")
        self.vector_store = FAISS.from_documents(split_docs, self.embeddings)
        
        # ä¿å­˜å‘é‡å­˜å‚¨
        self.vector_store.save_local(str(self.vector_store_path))
        if LANGUAGE_ADAPTER_AVAILABLE:
            print(get_message("vector_store_saved", str(self.vector_store_path)))
        else:
            print(f"ğŸ’¾ Vector store saved to: {self.vector_store_path}")
        
        return True
    
    def _load_or_create_vector_store(self):
        """åŠ è½½ç°æœ‰å‘é‡å­˜å‚¨æˆ–åˆ›å»ºæ–°çš„"""
        try:
            if (self.vector_store_path / "index.faiss").exists():
                if LANGUAGE_ADAPTER_AVAILABLE:
                    print(get_message("vector_store_loading"))
                else:
                    print("ğŸ“– Loading existing vector store...")
                self.vector_store = FAISS.load_local(
                    str(self.vector_store_path), 
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                if LANGUAGE_ADAPTER_AVAILABLE:
                    print(get_message("vector_store_loaded"))
                else:
                    print("âœ… Vector store loaded successfully")
            else:
                if LANGUAGE_ADAPTER_AVAILABLE:
                    print(get_message("vector_store_not_found"))
                else:
                    print("ğŸ†• No existing vector store found, will create new one...")
                self.add_documents_from_directory()
        except Exception as e:
            if LANGUAGE_ADAPTER_AVAILABLE:
                print(get_message("vector_store_load_failed", str(e)))
            else:
                print(f"âŒ Failed to load vector store: {e}")
            self.vector_store = None
    
    def search_commands(self, query: str, k: int = 5) -> List[Dict]:
        """åŸºäºæŸ¥è¯¢æ£€ç´¢ç›¸å…³å‘½ä»¤å’Œè§£å†³æ–¹æ¡ˆ"""
        if not self.vector_store:
            if LANGUAGE_ADAPTER_AVAILABLE:
                print(get_message("vector_store_not_initialized"))
            else:
                print("âŒ Vector store not initialized")
            return []
        
        try:
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            docs = self.vector_store.similarity_search(query, k=k)
            
            results = []
            for i, doc in enumerate(docs):
                # æå–å‘½ä»¤å’Œæè¿°
                commands = self._extract_commands_from_text(doc.page_content)
                
                result = {
                    "score": 1.0 - (i * 0.1),  # ç®€å•çš„ç›¸å…³æ€§è¯„åˆ†
                    "content": doc.page_content,
                    "commands": commands,
                    "source": doc.metadata.get("source", "unknown"),
                    "summary": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                }
                results.append(result)
            
            return results
            
        except Exception as e:
            print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _extract_commands_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–ç½‘ç»œå‘½ä»¤"""
        import re
        
        # å¸¸è§ç½‘ç»œå‘½ä»¤æ¨¡å¼
        command_patterns = [
            r'show\s+[\w\s-]+',
            r'debug\s+[\w\s-]+',
            r'ping\s+[\w.]+',
            r'traceroute\s+[\w.]+',
            r'telnet\s+[\w.]+',
            r'ssh\s+[\w.@]+',
            r'configure\s+terminal',
            r'interface\s+[\w/]+',
            r'router\s+\w+',
            r'ip\s+[\w\s-]+',
        ]
        
        commands = []
        for pattern in command_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            commands.extend(matches)
        
        # å»é‡å¹¶æ¸…ç†
        unique_commands = list(set(commands))
        return [cmd.strip() for cmd in unique_commands if len(cmd.strip()) > 5]

def create_sample_knowledge_base():
    """åˆ›å»ºç¤ºä¾‹çŸ¥è¯†åº“"""
    kb_path = Path("./knowledge_base")
    kb_path.mkdir(exist_ok=True)
    
    # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
    sample_docs = [
        {
            "filename": "ospf_troubleshooting.md",
            "content": """# OSPFæ•…éšœæ’é™¤æŒ‡å—

## OSPFé‚»å±…å…³ç³»é—®é¢˜

### é—®é¢˜æè¿°
OSPFé‚»å±…æ— æ³•å»ºç«‹æˆ–å¤„äºéFULLçŠ¶æ€

### è¯Šæ–­å‘½ä»¤
- `show ip ospf neighbor` - æŸ¥çœ‹OSPFé‚»å±…çŠ¶æ€
- `show ip ospf interface` - æŸ¥çœ‹OSPFæ¥å£é…ç½®
- `show ip ospf database` - æŸ¥çœ‹OSPFé“¾è·¯çŠ¶æ€æ•°æ®åº“
- `debug ip ospf adj` - è°ƒè¯•OSPFé‚»æ¥è¿‡ç¨‹

### å¸¸è§è§£å†³æ–¹æ¡ˆ
1. æ£€æŸ¥åŒºåŸŸIDæ˜¯å¦åŒ¹é…
2. éªŒè¯Helloé—´éš”å’ŒDeadé—´éš”
3. ç¡®è®¤è®¤è¯é…ç½®
4. æ£€æŸ¥ç½‘ç»œç±»å‹è®¾ç½®

## OSPFè·¯ç”±å®£å‘Šé—®é¢˜

### é—®é¢˜æè¿°
OSPFè·¯ç”±æœªæ­£ç¡®å®£å‘Šæˆ–å­¦ä¹ 

### è¯Šæ–­å‘½ä»¤
- `show ip route ospf` - æŸ¥çœ‹OSPFå­¦ä¹ çš„è·¯ç”±
- `show ip ospf database router` - æŸ¥çœ‹è·¯ç”±å™¨LSA
- `show running-config | section router ospf` - æŸ¥çœ‹OSPFé…ç½®

### è§£å†³æ–¹æ¡ˆ
1. æ£€æŸ¥networkè¯­å¥
2. éªŒè¯åŒºåŸŸé…ç½®
3. æ£€æŸ¥è·¯ç”±è¿‡æ»¤è®¾ç½®
"""
        },
        {
            "filename": "bgp_troubleshooting.md", 
            "content": """# BGPæ•…éšœæ’é™¤æŒ‡å—

## BGPé‚»å±…å»ºç«‹é—®é¢˜

### é—®é¢˜æè¿°
BGPé‚»å±…æ— æ³•å»ºç«‹æˆ–å¤„äºéEstablishedçŠ¶æ€

### è¯Šæ–­å‘½ä»¤
- `show ip bgp summary` - æŸ¥çœ‹BGPé‚»å±…æ‘˜è¦
- `show ip bgp neighbors` - æŸ¥çœ‹è¯¦ç»†é‚»å±…ä¿¡æ¯
- `debug ip bgp` - è°ƒè¯•BGPè¿›ç¨‹
- `show tcp brief` - æŸ¥çœ‹TCPè¿æ¥çŠ¶æ€

### å¸¸è§åŸå› 
1. ASå·ä¸åŒ¹é…
2. é‚»å±…åœ°å€é…ç½®é”™è¯¯
3. TCPè¿æ¥é—®é¢˜
4. è®¤è¯å¤±è´¥

## BGPè·¯ç”±ä¼ æ’­é—®é¢˜

### è¯Šæ–­å‘½ä»¤
- `show ip bgp` - æŸ¥çœ‹BGPè·¯ç”±è¡¨
- `show ip route bgp` - æŸ¥çœ‹BGPå­¦ä¹ çš„è·¯ç”±
- `show ip bgp neighbors advertised-routes` - æŸ¥çœ‹å®£å‘Šç»™é‚»å±…çš„è·¯ç”±
- `show ip bgp neighbors received-routes` - æŸ¥çœ‹ä»é‚»å±…æ¥æ”¶çš„è·¯ç”±
"""
        },
        {
            "filename": "interface_troubleshooting.md",
            "content": """# æ¥å£æ•…éšœæ’é™¤

## æ¥å£çŠ¶æ€é—®é¢˜

### è¯Šæ–­å‘½ä»¤
- `show interfaces` - æŸ¥çœ‹æ‰€æœ‰æ¥å£çŠ¶æ€
- `show ip interface brief` - æŸ¥çœ‹æ¥å£ç®€è¦ä¿¡æ¯
- `show interface description` - æŸ¥çœ‹æ¥å£æè¿°
- `show controllers` - æŸ¥çœ‹ç‰©ç†å±‚ä¿¡æ¯

## æ¥å£æ€§èƒ½é—®é¢˜

### è¯Šæ–­å‘½ä»¤
- `show interfaces counters` - æŸ¥çœ‹æ¥å£è®¡æ•°å™¨
- `show interfaces statistics` - æŸ¥çœ‹æ¥å£ç»Ÿè®¡ä¿¡æ¯
- `ping` - æµ‹è¯•è¿é€šæ€§
- `traceroute` - è¿½è¸ªè·¯å¾„
"""
        }
    ]
    
    # å†™å…¥ç¤ºä¾‹æ–‡æ¡£
    for doc in sample_docs:
        file_path = kb_path / doc["filename"]
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(doc["content"])
    
    print(f"âœ… ç¤ºä¾‹çŸ¥è¯†åº“å·²åˆ›å»ºåœ¨: {kb_path}")

if __name__ == "__main__":
    # åˆ›å»ºç¤ºä¾‹çŸ¥è¯†åº“
    create_sample_knowledge_base()
    
    # åˆå§‹åŒ–RAGç³»ç»Ÿ
    rag = NetworkTroubleshootingRAG()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "OSPFé‚»å±…æ— æ³•å»ºç«‹",
        "BGPè·¯ç”±å®£å‘Šé—®é¢˜", 
        "æ¥å£çŠ¶æ€å¼‚å¸¸",
        "è·¯ç”±å™¨è¿æ¥é—®é¢˜"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        results = rag.search_commands(query, k=3)
        
        for i, result in enumerate(results, 1):
            print(f"\nğŸ“‹ ç»“æœ {i} (ç›¸å…³æ€§: {result['score']:.2f}):")
            print(f"ğŸ“„ æ¥æº: {result['source']}")
            print(f"ğŸ“ æ‘˜è¦: {result['summary']}")
            if result['commands']:
                print(f"ğŸ”§ ç›¸å…³å‘½ä»¤: {', '.join(result['commands'][:3])}")
