# ğŸ”§ Technical Specifications / æŠ€æœ¯è§„æ ¼

## ğŸ“Š System Requirements / ç³»ç»Ÿè¦æ±‚

### Minimum Requirements / æœ€ä½è¦æ±‚
| Component | Requirement | ç»„ä»¶è¦æ±‚ |
|-----------|-------------|----------|
| **OS** | Linux/Windows/macOS | æ“ä½œç³»ç»Ÿ |
| **Python** | 3.8+ | Pythonç‰ˆæœ¬ |
| **RAM** | 4GB | å†…å­˜ |
| **Storage** | 2GB free space | å­˜å‚¨ç©ºé—´ |
| **Network** | GNS3 server access | ç½‘ç»œè®¿é—® |

### Recommended Requirements / æ¨èé…ç½®
| Component | Recommendation | æ¨èé…ç½® |
|-----------|----------------|----------|
| **OS** | Ubuntu 20.04+ / Windows 11 | æ“ä½œç³»ç»Ÿ |
| **Python** | 3.11+ | Pythonç‰ˆæœ¬ |
| **RAM** | 16GB+ | å†…å­˜ |
| **GPU** | CUDA-compatible (RTX series) | GPU |
| **Storage** | 10GB+ SSD | å­˜å‚¨ |
| **CPU** | 8+ cores | å¤„ç†å™¨ |

## ğŸ§  AI Model Support / AIæ¨¡å‹æ”¯æŒ

### Supported LLM Providers / æ”¯æŒçš„LLMæä¾›å•†
```yaml
LLM Models:
  DeepSeek:
    - deepseek-chat
    - deepseek-coder
  
  Ollama:
    - llama3.1
    - qwen2.5
    - gemma2
  
  OpenAI Compatible:
    - GPT-4
    - Claude (via OpenRouter)
    - Custom endpoints
```

### Embedding Models / åµŒå…¥æ¨¡å‹
```yaml
RAG Embeddings:
  Primary: BAAI/bge-m3
    - Multilingual support
    - 1024 dimensions
    - GPU optimized
  
  Alternative: sentence-transformers/all-MiniLM-L6-v2
    - Lightweight
    - Fast inference
    - CPU friendly
```

## ğŸ—ï¸ Architecture Details / æ¶æ„è¯¦æƒ…

### Core Components / æ ¸å¿ƒç»„ä»¶
```mermaid
graph TB
    subgraph "User Interface / ç”¨æˆ·ç•Œé¢"
        UI[Command Line Interface]
        LANG[Language Adapter]
    end
    
    subgraph "AI Processing / AIå¤„ç†"
        LLM[LLM Manager]
        RAG[RAG Knowledge Base]
        PROC[Intelligent Processor]
    end
    
    subgraph "Network Integration / ç½‘ç»œé›†æˆ"
        GNS3[GNS3 Agent Tools]
        TEL[Telnet Handler]
        API[REST API Client]
    end
    
    subgraph "Data Layer / æ•°æ®å±‚"
        VECTOR[Vector Store]
        CONFIG[Configuration Files]
        CACHE[Response Cache]
    end
    
    UI --> LANG
    LANG --> PROC
    PROC --> LLM
    PROC --> RAG
    RAG --> VECTOR
    PROC --> GNS3
    GNS3 --> TEL
    GNS3 --> API
```

### Data Flow / æ•°æ®æµ
```
1. User Input â†’ Language Detection â†’ Intent Analysis
2. Query â†’ RAG Search â†’ Command Selection
3. Command â†’ GNS3 Execution â†’ Response Collection
4. Response â†’ LLM Processing â†’ Formatted Output
5. Output â†’ Language Formatting â†’ User Display
```

## ğŸ“š Knowledge Base Specifications / çŸ¥è¯†åº“è§„æ ¼

### Document Processing / æ–‡æ¡£å¤„ç†
```yaml
Supported Formats:
  PDF:
    - Text extraction with PyPDF
    - Metadata preservation
    - Large file handling (>100MB)
  
  Text Files:
    - UTF-8 encoding
    - Automatic format detection
    - Line-by-line processing
  
  Markdown:
    - GitHub-flavored markdown
    - Code block preservation
    - Table extraction
  
  Word Documents:
    - DOCX format support
    - Style preservation
    - Image extraction
```

### Vector Storage / å‘é‡å­˜å‚¨
```yaml
FAISS Configuration:
  Index Type: IndexFlatIP
  Dimension: 1024 (BGE-M3)
  Distance Metric: Inner Product
  Storage: Local filesystem
  
Chunking Strategy:
  Chunk Size: 1000 characters
  Overlap: 200 characters
  Splitter: RecursiveCharacterTextSplitter
  
Search Parameters:
  Default K: 5 results
  Score Threshold: 0.7
  Max Results: 20
```

## ğŸŒ Network Protocol Support / ç½‘ç»œåè®®æ”¯æŒ

### GNS3 Integration / GNS3é›†æˆ
```yaml
API Support:
  Version: GNS3 2.2+
  Transport: HTTP/HTTPS
  Authentication: Basic/Token
  Endpoints:
    - /v2/projects
    - /v2/projects/{id}/nodes
    - /v2/projects/{id}/links
    - /v2/projects/{id}/status

Device Support:
  Cisco: IOS, IOS-XE, NX-OS
  Juniper: JunOS
  Arista: EOS
  Generic: Linux, Windows
```

### Telnet Configuration / Telneté…ç½®
```yaml
Connection Settings:
  Port: 23 (configurable)
  Timeout: 30 seconds
  Encoding: UTF-8
  Buffer Size: 8192 bytes
  
Authentication:
  Username/Password: Supported
  Enable Password: Supported
  SSH Fallback: Available
  
Command Execution:
  Batch Processing: Yes
  Error Handling: Robust
  Output Parsing: Intelligent
```

## ğŸ”’ Security Specifications / å®‰å…¨è§„æ ¼

### Data Protection / æ•°æ®ä¿æŠ¤
```yaml
Encryption:
  API Keys: Environment variables
  Passwords: Masked in logs
  Configurations: Local storage only
  
Access Control:
  File Permissions: 600 for secrets
  Network Access: Configurable whitelist
  API Limits: Rate limiting support
  
Privacy:
  Data Retention: User controlled
  Logging Level: Configurable
  Sensitive Data: Automatic redaction
```

### Compliance / åˆè§„æ€§
- **GDPR**: Personal data handling guidelines
- **SOC 2**: Security framework compatibility
- **ISO 27001**: Information security standards
- **NIST**: Cybersecurity framework alignment

## âš¡ Performance Benchmarks / æ€§èƒ½åŸºå‡†

### Response Times / å“åº”æ—¶é—´
```yaml
Operations:
  Language Detection: <1ms
  RAG Search: 50-200ms (GPU)
  LLM Processing: 1-5s (model dependent)
  Device Configuration: 2-30s (size dependent)
  
Throughput:
  Concurrent Users: 10+
  Batch Operations: 50+ devices
  Document Processing: 1000+ pages/hour
  Vector Search: 1000+ queries/second
```

### Resource Usage / èµ„æºä½¿ç”¨
```yaml
Memory:
  Base Application: 500MB
  RAG Knowledge Base: 2-8GB
  LLM Model Cache: 1-4GB
  Vector Store: 100MB-2GB
  
CPU:
  Idle: 1-2% (1 core)
  Active Processing: 20-80% (multi-core)
  RAG Search: 10-30% (with GPU)
  
GPU (if available):
  VRAM Usage: 2-6GB
  Utilization: 60-90% during embeddings
  CUDA Cores: Fully utilized
```

## ğŸ“ˆ Scalability / å¯æ‰©å±•æ€§

### Horizontal Scaling / æ°´å¹³æ‰©å±•
- **Multiple GNS3 Servers**: Load balancing support
- **Distributed RAG**: Multi-node vector search
- **LLM Load Balancing**: Round-robin model selection
- **Cache Clustering**: Redis-compatible caching

### Vertical Scaling / å‚ç›´æ‰©å±•
- **Memory Expansion**: Larger knowledge bases
- **GPU Scaling**: Multi-GPU embedding support
- **CPU Optimization**: Parallel processing
- **Storage Growth**: Elastic vector storage

## ğŸ”§ Development Specifications / å¼€å‘è§„æ ¼

### Code Quality / ä»£ç è´¨é‡
```yaml
Standards:
  PEP 8: Python style guide
  Type Hints: Full typing support
  Docstrings: Google style
  Testing: Unit and integration tests
  
Tools:
  Linting: flake8, black
  Type Checking: mypy
  Testing: pytest
  Documentation: Sphinx
```

### API Design / APIè®¾è®¡
```yaml
RESTful Principles:
  HTTP Methods: GET, POST, PUT, DELETE
  Status Codes: Standard HTTP codes
  Content Type: application/json
  Authentication: Bearer tokens
  
Versioning:
  URL Versioning: /api/v1/
  Backward Compatibility: 2 versions
  Deprecation Policy: 6 months notice
```

---

## ğŸ“‹ Feature Matrix / åŠŸèƒ½çŸ©é˜µ

| Feature | Basic | Professional | Enterprise |
|---------|-------|--------------|------------|
| **LLM Integration** | âœ… Ollama | âœ… + DeepSeek | âœ… + Custom APIs |
| **RAG Knowledge** | âœ… Basic | âœ… + GPU Acceleration | âœ… + Distributed |
| **Multi-Language** | âœ… EN/CN | âœ… + Auto-detection | âœ… + Custom Languages |
| **Device Support** | âœ… 10 devices | âœ… 100 devices | âœ… Unlimited |
| **Concurrent Users** | âœ… 1 user | âœ… 5 users | âœ… Unlimited |
| **Knowledge Base** | âœ… 100MB | âœ… 1GB | âœ… Unlimited |
| **API Access** | âŒ | âœ… Basic | âœ… Full REST API |
| **Custom Models** | âŒ | âœ… Limited | âœ… Full Support |
| **Enterprise Support** | âŒ | âŒ | âœ… 24/7 Support |

---

*Last Updated: August 2025 | æœ€åæ›´æ–°: 2025å¹´8æœˆ*
