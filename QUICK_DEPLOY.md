# ğŸš€ Quick Deployment Guide / å¿«é€Ÿéƒ¨ç½²æŒ‡å—

## ğŸ¯ 5-Minute Setup / 5åˆ†é’Ÿå¿«é€Ÿè®¾ç½®

### Prerequisites Check / ç¯å¢ƒæ£€æŸ¥
```bash
# Check Python version / æ£€æŸ¥Pythonç‰ˆæœ¬
python3 --version  # Should be 3.8+

# Check GPU availability (optional) / æ£€æŸ¥GPUå¯ç”¨æ€§ï¼ˆå¯é€‰ï¼‰
nvidia-smi

# Check GNS3 server / æ£€æŸ¥GNS3æœåŠ¡å™¨
curl http://YOUR_GNS3_SERVER:3080/v2/version
```

### Step 1: Clone & Setup / æ­¥éª¤1ï¼šå…‹éš†å’Œè®¾ç½®
```bash
# Clone repository / å…‹éš†ä»“åº“
git clone <your-repository-url>
cd GNS3/tools

# Create virtual environment / åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# or venv\Scripts\activate  # Windows

# Install dependencies / å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### Step 2: Environment Configuration / æ­¥éª¤2ï¼šç¯å¢ƒé…ç½®
```bash
# Copy environment template / å¤åˆ¶ç¯å¢ƒæ¨¡æ¿
cp .env.example .env

# Edit configuration / ç¼–è¾‘é…ç½®
nano .env
```

**Required Settings / å¿…éœ€è®¾ç½®:**
```bash
# GNS3 Configuration / GNS3é…ç½®
GNS3_SERVER_URL=http://192.168.101.1:3080
TELNET_HOST=192.168.102.1

# LLM Configuration / LLMé…ç½®
DEEPSEEK_API_KEY=your_deepseek_api_key_here
# or / æˆ–è€…
OLLAMA_BASE_URL=http://localhost:11434

# RAG Configuration / RAGé…ç½®
USE_RAG=true
```

### Step 3: Initialize RAG System / æ­¥éª¤3ï¼šåˆå§‹åŒ–RAGç³»ç»Ÿ
```bash
# Quick setup (recommended) / å¿«é€Ÿè®¾ç½®ï¼ˆæ¨èï¼‰
python setup_rag.py --all

# Or step by step / æˆ–è€…åˆ†æ­¥æ‰§è¡Œ
python setup_rag.py --install
python setup_rag.py --init
python setup_rag.py --enable
```

### Step 4: Add Knowledge Base / æ­¥éª¤4ï¼šæ·»åŠ çŸ¥è¯†åº“
```bash
# Create knowledge base directory / åˆ›å»ºçŸ¥è¯†åº“ç›®å½•
mkdir -p knowledge_base

# Add your network documentation / æ·»åŠ ç½‘ç»œæ–‡æ¡£
cp /path/to/your/network-docs/* knowledge_base/

# Supported formats / æ”¯æŒçš„æ ¼å¼
# - PDF files (*.pdf)
# - Text files (*.txt)
# - Markdown files (*.md)
# - Word documents (*.docx)
```

### Step 5: Launch Application / æ­¥éª¤5ï¼šå¯åŠ¨åº”ç”¨
```bash
# Start the intelligent agent / å¯åŠ¨æ™ºèƒ½ä»£ç†
python main.py
```

## ğŸ”§ Configuration Options / é…ç½®é€‰é¡¹

### Basic Configuration / åŸºç¡€é…ç½®
```ini
# .env file
GNS3_SERVER_URL=http://192.168.101.1:3080
TELNET_HOST=192.168.102.1
TELNET_PORT=23

# LLM Provider Selection / LLMæä¾›å•†é€‰æ‹©
DEFAULT_LLM=deepseek  # or 'ollama', 'openai'
DEEPSEEK_API_KEY=your_key
OLLAMA_BASE_URL=http://localhost:11434

# RAG Settings / RAGè®¾ç½®
USE_RAG=true
KNOWLEDGE_BASE_PATH=./knowledge_base
VECTOR_STORE_PATH=./vector_store
```

### Advanced Configuration / é«˜çº§é…ç½®
```ini
# rag_config.ini
[embeddings]
model_name = BAAI/bge-m3
device = cuda
max_length = 8192
batch_size = 32

[vector_store]
chunk_size = 1000
chunk_overlap = 200
search_k = 5

[llm]
temperature = 0.1
max_tokens = 1024
```

## ğŸ³ Docker Deployment / Dockeréƒ¨ç½²

### Quick Docker Setup / å¿«é€ŸDockerè®¾ç½®
```bash
# Build Docker image / æ„å»ºDockeré•œåƒ
docker build -t gns3-intelligent-agent .

# Run with environment file / ä½¿ç”¨ç¯å¢ƒæ–‡ä»¶è¿è¡Œ
docker run -d \
  --name gns3-agent \
  --env-file .env \
  -v $(pwd)/knowledge_base:/app/knowledge_base \
  -v $(pwd)/vector_store:/app/vector_store \
  gns3-intelligent-agent
```

### Docker Compose / Docker Compose
```yaml
# docker-compose.yml
version: '3.8'
services:
  gns3-agent:
    build: .
    container_name: gns3-intelligent-agent
    env_file: .env
    volumes:
      - ./knowledge_base:/app/knowledge_base
      - ./vector_store:/app/vector_store
      - ./device_configs:/app/device_configs
    ports:
      - "8080:8080"
    restart: unless-stopped
    
  # Optional: Add Redis for caching / å¯é€‰ï¼šæ·»åŠ Redisç¼“å­˜
  redis:
    image: redis:alpine
    container_name: redis-cache
    ports:
      - "6379:6379"
```

## â˜ï¸ Cloud Deployment / äº‘éƒ¨ç½²

### AWS EC2 Setup / AWS EC2è®¾ç½®
```bash
# Instance requirements / å®ä¾‹è¦æ±‚
# - Type: t3.large or better / ç±»å‹ï¼št3.largeæˆ–æ›´å¥½
# - Storage: 20GB+ EBS / å­˜å‚¨ï¼š20GB+ EBS
# - Security Group: Allow port 22, 8080 / å®‰å…¨ç»„ï¼šå…è®¸ç«¯å£22, 8080

# Install dependencies / å®‰è£…ä¾èµ–
sudo apt update
sudo apt install python3 python3-pip python3-venv git

# Setup application / è®¾ç½®åº”ç”¨
git clone <repository>
cd GNS3/tools
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Google Cloud Platform / è°·æ­Œäº‘å¹³å°
```bash
# Use Compute Engine / ä½¿ç”¨è®¡ç®—å¼•æ“
gcloud compute instances create gns3-agent \
  --machine-type=n1-standard-4 \
  --boot-disk-size=20GB \
  --image-family=ubuntu-2004-lts \
  --image-project=ubuntu-os-cloud \
  --tags=gns3-agent

# Setup firewall / è®¾ç½®é˜²ç«å¢™
gcloud compute firewall-rules create allow-gns3-agent \
  --allow=tcp:8080 \
  --target-tags=gns3-agent
```

## ğŸ” Troubleshooting / æ•…éšœæ’é™¤

### Common Issues / å¸¸è§é—®é¢˜

#### Issue: "CUDA not available" / é—®é¢˜ï¼š"CUDAä¸å¯ç”¨"
```bash
# Solution 1: Install CUDA toolkit / è§£å†³æ–¹æ¡ˆ1ï¼šå®‰è£…CUDAå·¥å…·åŒ…
# Visit: https://developer.nvidia.com/cuda-downloads

# Solution 2: Use CPU mode / è§£å†³æ–¹æ¡ˆ2ï¼šä½¿ç”¨CPUæ¨¡å¼
# Edit rag_config.ini:
[embeddings]
device = cpu
```

#### Issue: "GNS3 connection failed" / é—®é¢˜ï¼š"GNS3è¿æ¥å¤±è´¥"
```bash
# Check GNS3 server status / æ£€æŸ¥GNS3æœåŠ¡å™¨çŠ¶æ€
curl http://YOUR_GNS3_SERVER:3080/v2/version

# Verify network connectivity / éªŒè¯ç½‘ç»œè¿æ¥
ping YOUR_GNS3_SERVER

# Check firewall settings / æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
sudo ufw status
```

#### Issue: "LLM model not found" / é—®é¢˜ï¼š"LLMæ¨¡å‹æœªæ‰¾åˆ°"
```bash
# For Ollama / å¯¹äºOllama
ollama pull llama3.1
ollama list

# For DeepSeek / å¯¹äºDeepSeek
# Verify API key in .env file / éªŒè¯.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥
echo $DEEPSEEK_API_KEY
```

#### Issue: "Vector store initialization failed" / é—®é¢˜ï¼š"å‘é‡å­˜å‚¨åˆå§‹åŒ–å¤±è´¥"
```bash
# Clear existing vector store / æ¸…é™¤ç°æœ‰å‘é‡å­˜å‚¨
rm -rf vector_store/*

# Rebuild vector store / é‡å»ºå‘é‡å­˜å‚¨
python setup_rag.py --rebuild
```

### Debug Mode / è°ƒè¯•æ¨¡å¼
```bash
# Enable debug logging / å¯ç”¨è°ƒè¯•æ—¥å¿—
export DEBUG=true
python main.py

# Check logs / æ£€æŸ¥æ—¥å¿—
tail -f logs/gns3_agent.log
```

## ğŸ“Š Performance Tuning / æ€§èƒ½è°ƒä¼˜

### GPU Optimization / GPUä¼˜åŒ–
```ini
# rag_config.ini
[embeddings]
device = cuda
batch_size = 64  # Increase for more GPU memory
max_length = 8192
```

### Memory Optimization / å†…å­˜ä¼˜åŒ–
```ini
[vector_store]
chunk_size = 500  # Reduce for less memory usage
search_k = 3     # Reduce search results
```

### CPU Optimization / CPUä¼˜åŒ–
```bash
# Set environment variables / è®¾ç½®ç¯å¢ƒå˜é‡
export OMP_NUM_THREADS=4
export MKL_NUM_THREADS=4
```

## ğŸ”„ Update & Maintenance / æ›´æ–°ä¸ç»´æŠ¤

### Regular Updates / å®šæœŸæ›´æ–°
```bash
# Update repository / æ›´æ–°ä»“åº“
git pull origin main

# Update dependencies / æ›´æ–°ä¾èµ–
pip install -r requirements.txt --upgrade

# Rebuild vector store if needed / å¦‚éœ€è¦é‡å»ºå‘é‡å­˜å‚¨
python setup_rag.py --rebuild
```

### Backup & Restore / å¤‡ä»½ä¸æ¢å¤
```bash
# Backup configuration and data / å¤‡ä»½é…ç½®å’Œæ•°æ®
tar -czf gns3-agent-backup.tar.gz \
  .env rag_config.ini knowledge_base/ vector_store/

# Restore from backup / ä»å¤‡ä»½æ¢å¤
tar -xzf gns3-agent-backup.tar.gz
```

## ğŸ“ Support / æŠ€æœ¯æ”¯æŒ

### Getting Help / è·å–å¸®åŠ©
- **ğŸ“– Documentation**: Read full documentation in `PROJECT_OVERVIEW.md`
- **ğŸ› Issues**: Report bugs on GitHub Issues
- **ğŸ’¬ Community**: Join discussions for help
- **ğŸ“§ Email**: Contact support team

### Health Check / å¥åº·æ£€æŸ¥
```bash
# System health check / ç³»ç»Ÿå¥åº·æ£€æŸ¥
python -c "
import torch
import transformers
import langchain
print('âœ… All dependencies working')
print(f'PyTorch: {torch.__version__}')
print(f'CUDA Available: {torch.cuda.is_available()}')
"
```

---

## ğŸ‰ Success! / æˆåŠŸï¼

If you see this interface, your deployment is successful! / å¦‚æœçœ‹åˆ°æ­¤ç•Œé¢ï¼Œè¯´æ˜éƒ¨ç½²æˆåŠŸï¼

```
ğŸŒŸ GNS3 Intelligent Agent v6.0
   Network device management AI agent based on LangChain + Ollama
   Refactored version - Modular design

ğŸ’¡ Usage examples:
   â€¢ View network topology
   â€¢ List all devices
   â€¢ Get R-1 configuration
   
ğŸ’¬ Start conversation (enter 'quit' or 'exit' to exit):
--------------------------------------------------
```

**Next Steps / ä¸‹ä¸€æ­¥:**
1. Try some basic commands / å°è¯•ä¸€äº›åŸºæœ¬å‘½ä»¤
2. Add your network documentation / æ·»åŠ ç½‘ç»œæ–‡æ¡£
3. Configure advanced settings / é…ç½®é«˜çº§è®¾ç½®
4. Explore all features / æ¢ç´¢æ‰€æœ‰åŠŸèƒ½

---

*Happy networking! / ç½‘ç»œç®¡ç†æ„‰å¿«ï¼* ğŸš€
